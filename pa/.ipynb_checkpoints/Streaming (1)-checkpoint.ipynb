{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import json\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session & context mongodb atlas\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local')\n",
    "         .appName('BotnetDetection')\n",
    "         .config(\"spark.jars.packages\",\"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\")                     \n",
    "         .config(\"spark.mongodb.input.uri\",\"mongodb+srv://pram:pram123@cluster0.nrqu9.mongodb.net/tes?retryWrites=true&w=majority\")\n",
    "         .config(\"spark.mongodb.output.uri\",\"mongodb+srv://pram:pram123@cluster0.nrqu9.mongodb.net/tes?retryWrites=true&w=majority\")\n",
    "         .getOrCreate())\n",
    "spark.conf.set(\"spark.sql.caseSensitive\", \"true\")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session & context mongodb local\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local')\n",
    "         .appName('BotnetDetection')\n",
    "         .config(\"spark.jars.packages\",\"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\")                     \n",
    "         .config(\"spark.mongodb.input.uri\",\"mongodb://127.0.0.1:27017/tes1.hasil\")\n",
    "         .config(\"spark.mongodb.output.uri\",\"mongodb://127.0.0.1:27017/tes1.hasil\")\n",
    "         .getOrCreate())\n",
    "spark.conf.set(\"spark.sql.caseSensitive\", \"true\")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "         # .config(\"spark.mongodb.input.uri\",\"mongodb+srv://pram:pram123@cluster0.nrqu9.mongodb.net/tes?retryWrites=true&w=majority\")\n",
    "         # .config(\"spark.mongodb.output.uri\",\"mongodb+srv://pram:pram123@cluster0.nrqu9.mongodb.net/tes?retryWrites=true&w=majority\")"
   ]
  },
  {
   "source": [
    "# Training Phase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read.csv('data/SensorTrainDataResampling.csv', header=\"true\", inferSchema =True)\n",
    "#df_train = df_train.select([F.col(column).cast('double') for column in df_train.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature = ['average_packet_size','bwd_IAT_total','bwd_PSH_flags','bwd_URG_flags','bwd_header_length','bwd_packets_per_second','bwd_segment_size_avg','bwd_win_bytes','download_upload_ratio','flow_bytes_per_second','flow_duration','flow_pkts_per_second','fwd_IAT_total','fwd_PSH_flags','fwd_URG_flags','fwd_act_data_pkts','fwd_header_length','fwd_packets_per_second','fwd_seg_size_min','fwd_segment_size_avg','fwd_win_bytes','packet_length_variance','activePacket_max','activePacket_mean','activePacket_min','activePacket_std','bwd_IAT_max','bwd_IAT_mean','bwd_IAT_min','bwd_IAT_std','bwd_bulk_bulk_rate','bwd_bulk_bytes_per_bulk','bwd_bulk_packet_per_bulk','bwd_packet_length_max','bwd_packet_length_mean','bwd_packet_length_min','bwd_packet_length_std','bwd_subflow_subflow_bytes','bwd_subflow_subflow_packets','flagCount_ack','flagCount_cwr','flagCount_ece','flagCount_fin','flagCount_psh','flagCount_rst','flagCount_syn','flagCount_ugr','flow_IAT_max','flow_IAT_mean','flow_IAT_min','flow_IAT_std','fwd_IAT_max','fwd_IAT_mean','fwd_IAT_min','fwd_IAT_std','fwd_bulk_bulk_rate','fwd_bulk_bytes_per_bulk','fwd_bulk_packet_per_bulk','fwd_packet_length_max','fwd_packet_length_mean','fwd_packet_length_min','fwd_packet_length_std','fwd_subflow_subflow_bytes','fwd_subflow_subflow_packets','idlePacket_max','idlePacket_mean','idlePacket_min','idlePacket_std','packet_lenght_max','packet_lenght_mean','packet_lenght_min','packet_lenght_std','totalPacketFeature_backward','totalPacketFeature_forward','totalPacketFeature_length_of_backward','totalPacketFeature_length_of_forward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.select([F.col(column).cast('double') for column in df_train.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- _c0: double (nullable = true)\n |-- average_packet_size: double (nullable = true)\n |-- bwd_IAT_total: double (nullable = true)\n |-- bwd_PSH_flags: double (nullable = true)\n |-- bwd_URG_flags: double (nullable = true)\n |-- bwd_header_length: double (nullable = true)\n |-- bwd_packets_per_second: double (nullable = true)\n |-- bwd_segment_size_avg: double (nullable = true)\n |-- bwd_win_bytes: double (nullable = true)\n |-- download_upload_ratio: double (nullable = true)\n |-- flow_bytes_per_second: double (nullable = true)\n |-- flow_duration: double (nullable = true)\n |-- flow_pkts_per_second: double (nullable = true)\n |-- fwd_IAT_total: double (nullable = true)\n |-- fwd_PSH_flags: double (nullable = true)\n |-- fwd_URG_flags: double (nullable = true)\n |-- fwd_act_data_pkts: double (nullable = true)\n |-- fwd_header_length: double (nullable = true)\n |-- fwd_packets_per_second: double (nullable = true)\n |-- fwd_seg_size_min: double (nullable = true)\n |-- fwd_segment_size_avg: double (nullable = true)\n |-- fwd_win_bytes: double (nullable = true)\n |-- packet_length_variance: double (nullable = true)\n |-- activePacket_max: double (nullable = true)\n |-- activePacket_mean: double (nullable = true)\n |-- activePacket_min: double (nullable = true)\n |-- activePacket_std: double (nullable = true)\n |-- bwd_IAT_max: double (nullable = true)\n |-- bwd_IAT_mean: double (nullable = true)\n |-- bwd_IAT_min: double (nullable = true)\n |-- bwd_IAT_std: double (nullable = true)\n |-- bwd_bulk_bulk_rate: double (nullable = true)\n |-- bwd_bulk_bytes_per_bulk: double (nullable = true)\n |-- bwd_bulk_packet_per_bulk: double (nullable = true)\n |-- bwd_packet_length_max: double (nullable = true)\n |-- bwd_packet_length_mean: double (nullable = true)\n |-- bwd_packet_length_min: double (nullable = true)\n |-- bwd_packet_length_std: double (nullable = true)\n |-- bwd_subflow_subflow_bytes: double (nullable = true)\n |-- bwd_subflow_subflow_packets: double (nullable = true)\n |-- flagCount_ack: double (nullable = true)\n |-- flagCount_cwr: double (nullable = true)\n |-- flagCount_ece: double (nullable = true)\n |-- flagCount_fin: double (nullable = true)\n |-- flagCount_psh: double (nullable = true)\n |-- flagCount_rst: double (nullable = true)\n |-- flagCount_syn: double (nullable = true)\n |-- flagCount_ugr: double (nullable = true)\n |-- flow_IAT_max: double (nullable = true)\n |-- flow_IAT_mean: double (nullable = true)\n |-- flow_IAT_min: double (nullable = true)\n |-- flow_IAT_std: double (nullable = true)\n |-- fwd_IAT_max: double (nullable = true)\n |-- fwd_IAT_mean: double (nullable = true)\n |-- fwd_IAT_min: double (nullable = true)\n |-- fwd_IAT_std: double (nullable = true)\n |-- fwd_bulk_bulk_rate: double (nullable = true)\n |-- fwd_bulk_bytes_per_bulk: double (nullable = true)\n |-- fwd_bulk_packet_per_bulk: double (nullable = true)\n |-- fwd_packet_length_max: double (nullable = true)\n |-- fwd_packet_length_mean: double (nullable = true)\n |-- fwd_packet_length_min: double (nullable = true)\n |-- fwd_packet_length_std: double (nullable = true)\n |-- fwd_subflow_subflow_bytes: double (nullable = true)\n |-- fwd_subflow_subflow_packets: double (nullable = true)\n |-- idlePacket_max: double (nullable = true)\n |-- idlePacket_mean: double (nullable = true)\n |-- idlePacket_min: double (nullable = true)\n |-- idlePacket_std: double (nullable = true)\n |-- packet_lenght_max: double (nullable = true)\n |-- packet_lenght_mean: double (nullable = true)\n |-- packet_lenght_min: double (nullable = true)\n |-- packet_lenght_std: double (nullable = true)\n |-- totalPacketFeature_backward: double (nullable = true)\n |-- totalPacketFeature_forward: double (nullable = true)\n |-- totalPacketFeature_length_of_backward: double (nullable = true)\n |-- totalPacketFeature_length_of_forward: double (nullable = true)\n |-- label: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImp = ['fwd_win_bytes','idlePacket_max','fwd_header_length','bwd_packets_per_second','flow_bytes_per_second','bwd_win_bytes','flow_IAT_max']"
   ]
  },
  {
   "source": [
    "## EKSTRAK FITUR UNTUK DATA TRAINING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengekstrak fitur data training\n",
    "dfImp = df_train.select(F.col('fwd_win_bytes'), F.col('idlePacket_max'), F.col('fwd_header_length'),F.col('bwd_packets_per_second'), F.col('flow_bytes_per_second'), F.col('bwd_win_bytes'), F.col('flow_IAT_max'),F.col('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfImp = dfImp.select([F.col(column).cast('double') for column in dfImp.columns])"
   ]
  },
  {
   "source": [
    "## Normalize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector_assembler = VectorAssembler(inputCols=feature, outputCol=\"SS_features\")\n",
    "#df_train = vector_assembler.transform(df_train)\n",
    "#scaler = StandardScaler(inputCol=\"SS_features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler = VectorAssembler(inputCols=featureImp, outputCol=\"SS_features\")\n",
    "dfImp = vector_assembler.transform(dfImp)\n",
    "scaler = StandardScaler(inputCol=\"SS_features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = scaler.fit(dfImp).transform(dfImp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = scaler.fit(df_train).transform(df_train)"
   ]
  },
  {
   "source": [
    "## Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Dataset Count: 174477\n",
      "Test Dataset Count: 43657\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "(training_data, test_data) = train.randomSplit([0.8,0.2], seed =2020)\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol = 'scaledFeatures', labelCol = 'label', maxDepth =20)\n",
    "dtModel = dt.fit(training_data)\n",
    "dt_predictions = dtModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decision Tree Accuracy: 0.9775522825663696\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "multi_evaluator = MulticlassClassificationEvaluator(labelCol = 'label', metricName = 'accuracy')\n",
    "print('Decision Tree Accuracy:', multi_evaluator.evaluate(dt_predictions))"
   ]
  },
  {
   "source": [
    "# Streaming Kafka (Testing)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFormatSchema = spark.read.json(\"schema/schema.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = (spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") # kafka server\n",
    "  .option(\"subscribe\", \"netflowmeter\") # topic\n",
    "  .option(\"startingOffsets\", \"latest\") \n",
    "  .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedData = rawData.selectExpr(\"cast (value as string) as json\").select(F.from_json(\"json\",jsonFormatSchema.schema).alias(\"data\")).select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- dst_ip: string (nullable = true)\n |-- dst_port: long (nullable = true)\n |-- extractFeature: struct (nullable = true)\n |    |-- ActivePacket: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- IdlePacket: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- activePacket: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- average_packet_size: double (nullable = true)\n |    |-- bwd_IAT: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- bwd_IAT_total: double (nullable = true)\n |    |-- bwd_PSH_flags: double (nullable = true)\n |    |-- bwd_URG_flags: double (nullable = true)\n |    |-- bwd_bulk: struct (nullable = true)\n |    |    |-- bulk_rate: long (nullable = true)\n |    |    |-- bytes_per_bulk: long (nullable = true)\n |    |    |-- packet_per_bulk: long (nullable = true)\n |    |-- bwd_header_length: double (nullable = true)\n |    |-- bwd_packet_length: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- bwd_packets_per_second: double (nullable = true)\n |    |-- bwd_segment_size_avg: double (nullable = true)\n |    |-- bwd_subflow: struct (nullable = true)\n |    |    |-- subflow_bytes: long (nullable = true)\n |    |    |-- subflow_packets: long (nullable = true)\n |    |-- bwd_win_bytes: long (nullable = true)\n |    |-- download_upload_ratio: double (nullable = true)\n |    |-- flagCount: struct (nullable = true)\n |    |    |-- ack: long (nullable = true)\n |    |    |-- cwr: long (nullable = true)\n |    |    |-- ece: long (nullable = true)\n |    |    |-- fin: long (nullable = true)\n |    |    |-- psh: long (nullable = true)\n |    |    |-- rst: long (nullable = true)\n |    |    |-- syn: long (nullable = true)\n |    |    |-- ugr: long (nullable = true)\n |    |-- flow_IAT: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- flow_bytes_per_second: double (nullable = true)\n |    |-- flow_duration: long (nullable = true)\n |    |-- flow_pkts_per_second: double (nullable = true)\n |    |-- fwd_IAT: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- fwd_IAT_total: double (nullable = true)\n |    |-- fwd_PSH_flags: double (nullable = true)\n |    |-- fwd_URG_flags: double (nullable = true)\n |    |-- fwd_act_data_pkts: long (nullable = true)\n |    |-- fwd_bulk: struct (nullable = true)\n |    |    |-- bulk_rate: long (nullable = true)\n |    |    |-- bytes_per_bulk: long (nullable = true)\n |    |    |-- packet_per_bulk: long (nullable = true)\n |    |-- fwd_header_length: double (nullable = true)\n |    |-- fwd_packet_length: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- fwd_packets_per_second: double (nullable = true)\n |    |-- fwd_seg_size_min: long (nullable = true)\n |    |-- fwd_segment_size_avg: double (nullable = true)\n |    |-- fwd_subflow: struct (nullable = true)\n |    |    |-- subflow_bytes: long (nullable = true)\n |    |    |-- subflow_packets: long (nullable = true)\n |    |-- fwd_win_bytes: long (nullable = true)\n |    |-- idlePacket: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- packet_lenght: struct (nullable = true)\n |    |    |-- max: double (nullable = true)\n |    |    |-- mean: double (nullable = true)\n |    |    |-- min: double (nullable = true)\n |    |    |-- std: double (nullable = true)\n |    |-- packet_length_variance: double (nullable = true)\n |    |-- totalPacketFeature: struct (nullable = true)\n |    |    |-- backward: long (nullable = true)\n |    |    |-- forward: long (nullable = true)\n |    |    |-- length_of_backward: double (nullable = true)\n |    |    |-- length_of_forward: double (nullable = true)\n |-- flow_id: string (nullable = true)\n |-- label: string (nullable = true)\n |-- protocol: long (nullable = true)\n |-- src_ip: string (nullable = true)\n |-- src_port: long (nullable = true)\n |-- timestamp: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "parsedData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengurutkan fitur agar tertata\n",
    "featureExtraction = parsedData.select(F.col('flow_id'), F.col('src_ip'), F.col('src_port'), F.col('dst_ip'), F.col('dst_port'), F.col('protocol'), F.col('timestamp'),F.col(\"extractFeature.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data diflatkan biar ga bercabang --> pada extract feature\n",
    "def flatten_df(nested_df):\n",
    "    flat_cols = [c[0] for c in nested_df.dtypes if c[1][:6] != 'struct']\n",
    "    nested_cols = [c[0] for c in nested_df.dtypes if c[1][:6] == 'struct']\n",
    "\n",
    "    flat_df = nested_df.select(flat_cols +\n",
    "                               [F.col(nc+'.'+c).alias(nc+'_'+c)\n",
    "                                for nc in nested_cols\n",
    "                                for c in nested_df.select(nc+'.*').columns])\n",
    "    return flat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flat = flatten_df(featureExtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_columns = ['ActivePacket_max', 'ActivePacket_mean', 'ActivePacket_min', 'ActivePacket_std', 'IdlePacket_max', 'IdlePacket_mean', 'IdlePacket_min','IdlePacket_std']\n",
    "data_flat = data_flat.drop(*duplicate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- flow_id: string (nullable = true)\n |-- src_ip: string (nullable = true)\n |-- src_port: long (nullable = true)\n |-- dst_ip: string (nullable = true)\n |-- dst_port: long (nullable = true)\n |-- protocol: long (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- average_packet_size: double (nullable = true)\n |-- bwd_IAT_total: double (nullable = true)\n |-- bwd_PSH_flags: double (nullable = true)\n |-- bwd_URG_flags: double (nullable = true)\n |-- bwd_header_length: double (nullable = true)\n |-- bwd_packets_per_second: double (nullable = true)\n |-- bwd_segment_size_avg: double (nullable = true)\n |-- bwd_win_bytes: long (nullable = true)\n |-- download_upload_ratio: double (nullable = true)\n |-- flow_bytes_per_second: double (nullable = true)\n |-- flow_duration: long (nullable = true)\n |-- flow_pkts_per_second: double (nullable = true)\n |-- fwd_IAT_total: double (nullable = true)\n |-- fwd_PSH_flags: double (nullable = true)\n |-- fwd_URG_flags: double (nullable = true)\n |-- fwd_act_data_pkts: long (nullable = true)\n |-- fwd_header_length: double (nullable = true)\n |-- fwd_packets_per_second: double (nullable = true)\n |-- fwd_seg_size_min: long (nullable = true)\n |-- fwd_segment_size_avg: double (nullable = true)\n |-- fwd_win_bytes: long (nullable = true)\n |-- packet_length_variance: double (nullable = true)\n |-- activePacket_max: double (nullable = true)\n |-- activePacket_mean: double (nullable = true)\n |-- activePacket_min: double (nullable = true)\n |-- activePacket_std: double (nullable = true)\n |-- bwd_IAT_max: double (nullable = true)\n |-- bwd_IAT_mean: double (nullable = true)\n |-- bwd_IAT_min: double (nullable = true)\n |-- bwd_IAT_std: double (nullable = true)\n |-- bwd_bulk_bulk_rate: long (nullable = true)\n |-- bwd_bulk_bytes_per_bulk: long (nullable = true)\n |-- bwd_bulk_packet_per_bulk: long (nullable = true)\n |-- bwd_packet_length_max: double (nullable = true)\n |-- bwd_packet_length_mean: double (nullable = true)\n |-- bwd_packet_length_min: double (nullable = true)\n |-- bwd_packet_length_std: double (nullable = true)\n |-- bwd_subflow_subflow_bytes: long (nullable = true)\n |-- bwd_subflow_subflow_packets: long (nullable = true)\n |-- flagCount_ack: long (nullable = true)\n |-- flagCount_cwr: long (nullable = true)\n |-- flagCount_ece: long (nullable = true)\n |-- flagCount_fin: long (nullable = true)\n |-- flagCount_psh: long (nullable = true)\n |-- flagCount_rst: long (nullable = true)\n |-- flagCount_syn: long (nullable = true)\n |-- flagCount_ugr: long (nullable = true)\n |-- flow_IAT_max: double (nullable = true)\n |-- flow_IAT_mean: double (nullable = true)\n |-- flow_IAT_min: double (nullable = true)\n |-- flow_IAT_std: double (nullable = true)\n |-- fwd_IAT_max: double (nullable = true)\n |-- fwd_IAT_mean: double (nullable = true)\n |-- fwd_IAT_min: double (nullable = true)\n |-- fwd_IAT_std: double (nullable = true)\n |-- fwd_bulk_bulk_rate: long (nullable = true)\n |-- fwd_bulk_bytes_per_bulk: long (nullable = true)\n |-- fwd_bulk_packet_per_bulk: long (nullable = true)\n |-- fwd_packet_length_max: double (nullable = true)\n |-- fwd_packet_length_mean: double (nullable = true)\n |-- fwd_packet_length_min: double (nullable = true)\n |-- fwd_packet_length_std: double (nullable = true)\n |-- fwd_subflow_subflow_bytes: long (nullable = true)\n |-- fwd_subflow_subflow_packets: long (nullable = true)\n |-- idlePacket_max: double (nullable = true)\n |-- idlePacket_mean: double (nullable = true)\n |-- idlePacket_min: double (nullable = true)\n |-- idlePacket_std: double (nullable = true)\n |-- packet_lenght_max: double (nullable = true)\n |-- packet_lenght_mean: double (nullable = true)\n |-- packet_lenght_min: double (nullable = true)\n |-- packet_lenght_std: double (nullable = true)\n |-- totalPacketFeature_backward: long (nullable = true)\n |-- totalPacketFeature_forward: long (nullable = true)\n |-- totalPacketFeature_length_of_backward: double (nullable = true)\n |-- totalPacketFeature_length_of_forward: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "data_flat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleksi Fitur (perlu coloumn label?)\n",
    "dataSelect =  data_flat.select(F.col('flow_id'), F.col('src_ip'), F.col('src_port'), F.col('dst_ip'), F.col('dst_port'), F.col('protocol'), F.col('timestamp'),F.col('fwd_win_bytes'), F.col('idlePacket_max'), F.col('fwd_header_length'),F.col('bwd_packets_per_second'), F.col('flow_bytes_per_second'), F.col('bwd_win_bytes'), F.col('flow_IAT_max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngevector data berdasarkan df train\n",
    "vector_assembler = VectorAssembler(inputCols=featureImp, outputCol=\"SS_features\")\n",
    "\n",
    "dataSelect = vector_assembler.transform(dataSelect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- flow_id: string (nullable = true)\n |-- src_ip: string (nullable = true)\n |-- src_port: long (nullable = true)\n |-- dst_ip: string (nullable = true)\n |-- dst_port: long (nullable = true)\n |-- protocol: long (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- fwd_win_bytes: long (nullable = true)\n |-- idlePacket_max: double (nullable = true)\n |-- fwd_header_length: double (nullable = true)\n |-- bwd_packets_per_second: double (nullable = true)\n |-- flow_bytes_per_second: double (nullable = true)\n |-- bwd_win_bytes: long (nullable = true)\n |-- flow_IAT_max: double (nullable = true)\n |-- SS_features: vector (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "dataSelect.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data sensor berdasar df_train\n",
    "#data_flat = scaler.fit(df_train).transform(data_flat)\n",
    "\n",
    "#normalisasi data seleksi fitur\n",
    "dataSelect = scaler.fit(dfImp).transform(dataSelect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = dtModel.transform(dataSelect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- flow_id: string (nullable = true)\n |-- src_ip: string (nullable = true)\n |-- src_port: long (nullable = true)\n |-- dst_ip: string (nullable = true)\n |-- dst_port: long (nullable = true)\n |-- protocol: long (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- fwd_win_bytes: long (nullable = true)\n |-- idlePacket_max: double (nullable = true)\n |-- fwd_header_length: double (nullable = true)\n |-- bwd_packets_per_second: double (nullable = true)\n |-- flow_bytes_per_second: double (nullable = true)\n |-- bwd_win_bytes: long (nullable = true)\n |-- flow_IAT_max: double (nullable = true)\n |-- SS_features: vector (nullable = true)\n |-- scaledFeatures: vector (nullable = true)\n |-- rawPrediction: vector (nullable = true)\n |-- probability: vector (nullable = true)\n |-- prediction: double (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "pred_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "from decimal import Decimal\n",
    "\n",
    "def date_udf(x):\n",
    "  dec = Decimal(x)\n",
    "  c = datetime.fromtimestamp(int(dec)/1000).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "  return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_udf = F.udf(date_udf, StringType())\n",
    "pred_df= pred_df.withColumn('datetime', datetime_udf(pred_df['timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df_1 = pred_df.select(F.col('flow_id'), F.col('src_ip'), F.col('src_port'), F.col('dst_ip'), F.col('dst_port'), F.col('protocol'), F.col('datetime'), F.col('prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-82d06709cf82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_df_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeachBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_mongo_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def write_mongo_row(df, epoch_id):\n",
    "    df.write.format(\"mongo\").mode(\"append\").option(\"database\",\"tes\").option(\"collection\",\"hasil\").save()\n",
    "    pass\n",
    "\n",
    "query=pred_df_1.writeStream.foreachBatch(write_mongo_row).start()\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = pred_df.writeStream.queryName(\"sas\").format(\"memory\").outputMode(\"append\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+\n|datetime|\n+--------+\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "#raw = spark.sql(\"select * from sas\")\n",
    "#raw[['datetime']].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}